{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\alexv\\PycharmProjects\\FeatureSelection-MMO\\Dados\\train.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 201 entries, 0 to 200\n",
      "Columns: 195002 entries, beer_id to target\n",
      "dtypes: float64(195001), int64(1)\n",
      "memory usage: 299.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "19.0    8\n3.0     8\n22.0    8\n27.0    8\n15.0    7\n14.0    7\n8.0     7\n1.0     7\n12.0    7\n17.0    7\n13.0    7\n5.0     7\n16.0    7\n29.0    7\n24.0    7\n4.0     6\n20.0    6\n26.0    6\n25.0    6\n30.0    6\n28.0    6\n7.0     6\n31.0    6\n11.0    6\n32.0    6\n18.0    5\n6.0     5\n9.0     5\n2.0     5\n21.0    4\n23.0    4\n10.0    4\nName: target, dtype: int64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Dataset um tanto desbalanceado"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "df.set_index(\"beer_id\", drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "X = df.drop(columns=['target'])\n",
    "y = df.target\n",
    "\n",
    "del df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Vamos separar em treino e validação. Pegar 25% dos exemplos de cada cerveja\n",
    "targets = y.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "X_val = X.loc[0:1].copy()\n",
    "y_val = y.loc[0:1].copy()\n",
    "\n",
    "# nesse trecho estou separando a base de treino em validacao e treino manualmente,\n",
    "# pois deve-se haver 25% de individuos de cada classe na base de validacao.\n",
    "for cerveja in targets:\n",
    "    beers = X[y == cerveja]\n",
    "    qtd_val = round(len(beers) * 0.25)\n",
    "    val_sampled = beers.sample(qtd_val)\n",
    "    y_val = pd.concat([y_val, y.loc[val_sampled.index]])\n",
    "    X.drop(val_sampled.index, inplace=True)\n",
    "    y.drop(val_sampled.index, inplace=True)\n",
    "    X_val = pd.concat([X_val,val_sampled])\n",
    "\n",
    "X_val.drop([0,1], inplace=True)\n",
    "y_val.drop([0,1], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "((144, 195000), (57, 195000))"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X_val.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "((144,), (57,))"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, y_val.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Devemos fazer a divisão entre treino e validação antes de passar o over sampler, pois precisamos garantir representabilidade do dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# balanceando com RandomOverSampler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "balancer = RandomOverSampler(random_state=42)\n",
    "X_train_rzd, y_train_rzd = balancer.fit_resample(X,y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "X_val_rzd, y_val_rzd = balancer.fit_resample(X_val, y_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "25.0    2\n28.0    2\n26.0    2\n10.0    2\n9.0     2\n20.0    2\n4.0     2\n17.0    2\n12.0    2\n1.0     2\n22.0    2\n21.0    2\n3.0     2\n5.0     2\n13.0    2\n14.0    2\n2.0     2\n7.0     2\n8.0     2\n18.0    2\n31.0    2\n11.0    2\n19.0    2\n15.0    2\n6.0     2\n23.0    2\n27.0    2\n16.0    2\n29.0    2\n24.0    2\n32.0    2\n30.0    2\nName: target, dtype: int64"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_rzd.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "25.0    6\n28.0    6\n30.0    6\n14.0    6\n24.0    6\n26.0    6\n10.0    6\n9.0     6\n20.0    6\n15.0    6\n4.0     6\n17.0    6\n12.0    6\n1.0     6\n22.0    6\n3.0     6\n5.0     6\n32.0    6\n13.0    6\n2.0     6\n7.0     6\n8.0     6\n19.0    6\n18.0    6\n31.0    6\n11.0    6\n6.0     6\n23.0    6\n27.0    6\n16.0    6\n29.0    6\n21.0    6\nName: target, dtype: int64"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_rzd.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# salvando em um csv\n",
    "data_val = pd.concat([X_val_rzd, y_val_rzd], axis=1)\n",
    "data = pd.concat([X_train_rzd, y_train_rzd], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "data.to_csv(\"../Dados/DataTrain.csv\", index=False)\n",
    "data_val.to_csv(\"../Dados/DataVal.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "0      25.0\n1      28.0\n2      29.0\n3      16.0\n4      27.0\n       ... \n187    30.0\n188    31.0\n189    31.0\n190    32.0\n191    32.0\nName: target, Length: 192, dtype: float64"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "X_val_final = pd.read_csv('../Dados/DataVal.csv', dtype='float16')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "X_val_final.to_parquet(\"DataVal.parquet\", index=False, compression=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_parquet\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../Dados/DataTrain.parquet\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfastparquet\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\datascience\\lib\\site-packages\\pandas\\io\\parquet.py:493\u001B[0m, in \u001B[0;36mread_parquet\u001B[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001B[0m\n\u001B[0;32m    446\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    447\u001B[0m \u001B[38;5;124;03mLoad a parquet object from the file path, returning a DataFrame.\u001B[39;00m\n\u001B[0;32m    448\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    489\u001B[0m \u001B[38;5;124;03mDataFrame\u001B[39;00m\n\u001B[0;32m    490\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    491\u001B[0m impl \u001B[38;5;241m=\u001B[39m get_engine(engine)\n\u001B[1;32m--> 493\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimpl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    495\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    496\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    497\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_nullable_dtypes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_nullable_dtypes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    498\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    499\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\datascience\\lib\\site-packages\\pandas\\io\\parquet.py:347\u001B[0m, in \u001B[0;36mFastParquetImpl.read\u001B[1;34m(self, path, columns, storage_options, **kwargs)\u001B[0m\n\u001B[0;32m    343\u001B[0m     path \u001B[38;5;241m=\u001B[39m handles\u001B[38;5;241m.\u001B[39mhandle\n\u001B[0;32m    345\u001B[0m parquet_file \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi\u001B[38;5;241m.\u001B[39mParquetFile(path, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparquet_kwargs)\n\u001B[1;32m--> 347\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mparquet_file\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_pandas\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m handles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    350\u001B[0m     handles\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\datascience\\lib\\site-packages\\fastparquet\\api.py:771\u001B[0m, in \u001B[0;36mParquetFile.to_pandas\u001B[1;34m(self, columns, categories, filters, index, row_filter)\u001B[0m\n\u001B[0;32m    767\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m    768\u001B[0m     parts \u001B[38;5;241m=\u001B[39m {name: (v \u001B[38;5;28;01mif\u001B[39;00m name\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-catdef\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    769\u001B[0m                     \u001B[38;5;28;01melse\u001B[39;00m v[start:start \u001B[38;5;241m+\u001B[39m thislen])\n\u001B[0;32m    770\u001B[0m              \u001B[38;5;28;01mfor\u001B[39;00m (name, v) \u001B[38;5;129;01min\u001B[39;00m views\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[1;32m--> 771\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_row_group_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcategories\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    772\u001B[0m \u001B[43m                             \u001B[49m\u001B[43massign\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpartition_meta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpartition_meta\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    773\u001B[0m \u001B[43m                             \u001B[49m\u001B[43mrow_filter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minfile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minfile\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    774\u001B[0m     start \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m thislen\n\u001B[0;32m    775\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\datascience\\lib\\site-packages\\fastparquet\\api.py:375\u001B[0m, in \u001B[0;36mParquetFile.read_row_group_file\u001B[1;34m(self, rg, columns, categories, index, assign, partition_meta, row_filter, infile)\u001B[0m\n\u001B[0;32m    372\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    373\u001B[0m f \u001B[38;5;241m=\u001B[39m infile \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopen(fn, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m--> 375\u001B[0m \u001B[43mcore\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_row_group\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    376\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcategories\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mschema\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcats\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    377\u001B[0m \u001B[43m    \u001B[49m\u001B[43mselfmade\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselfmade\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    378\u001B[0m \u001B[43m    \u001B[49m\u001B[43massign\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43massign\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheme\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfile_scheme\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpartition_meta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpartition_meta\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    379\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrow_filter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrow_filter\u001B[49m\n\u001B[0;32m    380\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    381\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ret:\n\u001B[0;32m    382\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\datascience\\lib\\site-packages\\fastparquet\\core.py:608\u001B[0m, in \u001B[0;36mread_row_group\u001B[1;34m(file, rg, columns, categories, schema_helper, cats, selfmade, index, assign, scheme, partition_meta, row_filter)\u001B[0m\n\u001B[0;32m    606\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m assign \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    607\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGoing with pre-allocation!\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m--> 608\u001B[0m \u001B[43mread_row_group_arrays\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcategories\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mschema_helper\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    609\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mcats\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mselfmade\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43massign\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43massign\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrow_filter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrow_filter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    611\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m cat \u001B[38;5;129;01min\u001B[39;00m cats:\n\u001B[0;32m    612\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m cat \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m assign:\n\u001B[0;32m    613\u001B[0m         \u001B[38;5;66;03m# do no need to have partition columns in output\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\datascience\\lib\\site-packages\\fastparquet\\core.py:580\u001B[0m, in \u001B[0;36mread_row_group_arrays\u001B[1;34m(file, rg, columns, categories, schema_helper, cats, selfmade, assign, row_filter)\u001B[0m\n\u001B[0;32m    577\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m columns:\n\u001B[0;32m    578\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m--> 580\u001B[0m \u001B[43mread_col\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcolumn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mschema_helper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_cat\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m-catdef\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    581\u001B[0m \u001B[43m         \u001B[49m\u001B[43mselfmade\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mselfmade\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43massign\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    582\u001B[0m \u001B[43m         \u001B[49m\u001B[43mcatdef\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m-catdef\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    583\u001B[0m \u001B[43m         \u001B[49m\u001B[43mrow_filter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrow_filter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    585\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _is_map_like(schema_helper, column):\n\u001B[0;32m    586\u001B[0m     \u001B[38;5;66;03m# TODO: could be done in fast loop in _assemble_objects?\u001B[39;00m\n\u001B[0;32m    587\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m maps:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\datascience\\lib\\site-packages\\fastparquet\\core.py:440\u001B[0m, in \u001B[0;36mread_col\u001B[1;34m(column, schema_helper, infile, use_cat, selfmade, assign, catdef, row_filter)\u001B[0m\n\u001B[0;32m    436\u001B[0m off \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m((cmd\u001B[38;5;241m.\u001B[39mdictionary_page_offset \u001B[38;5;129;01mor\u001B[39;00m cmd\u001B[38;5;241m.\u001B[39mdata_page_offset,\n\u001B[0;32m    437\u001B[0m            cmd\u001B[38;5;241m.\u001B[39mdata_page_offset))\n\u001B[0;32m    439\u001B[0m infile\u001B[38;5;241m.\u001B[39mseek(off)\n\u001B[1;32m--> 440\u001B[0m column_binary \u001B[38;5;241m=\u001B[39m \u001B[43minfile\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcmd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtotal_compressed_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    441\u001B[0m infile \u001B[38;5;241m=\u001B[39m encoding\u001B[38;5;241m.\u001B[39mNumpyIO(column_binary)\n\u001B[0;32m    442\u001B[0m rows \u001B[38;5;241m=\u001B[39m row_filter\u001B[38;5;241m.\u001B[39msum() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(row_filter, np\u001B[38;5;241m.\u001B[39mndarray) \u001B[38;5;28;01melse\u001B[39;00m cmd\u001B[38;5;241m.\u001B[39mnum_values\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"../Dados/DataTrain.parquet\", engine='fastparquet')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}